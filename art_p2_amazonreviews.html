<html>
  <head>
    <style>
    .center {
      display: block;
      margin-left: auto;
      margin-right: auto;
      /* width: 50%; */
    }</style>

  </head>
  <body>
    <h1 id="amazon-reviews-classification-and-rating-predictions">Amazon Reviews, Classification and Rating Predictions</h1>
<p>Working with one of my fellow enthusiast Data scientists I evaluated several models to classify the free text Amazon predictions into two classes: positive and negative, and another few models to predict the star rating for these same reviews. This project uses the <strong>Multilingual Amazon Reviews Corpus</strong>, and the full notebook can be found in this <a href="https://github.com/valeriaortizl/amazon_ratings_predictions">repo.</a></p>
<h2 id="eda">EDA</h2>
<p>This dataset provided us with identical dev, test and train files, were the dev and test ones had 5.000 entries each, and the train one had 200.000, plus the star rating classes were perfectly balanced too! This is a peek at what these tables had to offer:</p>
<div>
<table>
  <thead>
    <tr style="text-align: right; width: 70%;">
      <th></th>
      <th>review_id</th>
      <th>product_id</th>
      <th>reviewer_id</th>
      <th>stars</th>
      <th>review_body</th>
      <th>review_title</th>
      <th>language</th>
      <th>product_category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>es_0417480</td>
      <td>product_es_0873923</td>
      <td>reviewer_es_0672978</td>
      <td>1</td>
      <td>Malisimo, muy grande demasiado aparatoso y mal...</td>
      <td>Mala compra</td>
      <td>es</td>
      <td>wireless</td>
    </tr>
    <tr>
      <th>1</th>
      <td>es_0180432</td>
      <td>product_es_0713146</td>
      <td>reviewer_es_0100858</td>
      <td>1</td>
      <td>No he recibido el pedido no la devolución</td>
      <td>No lo he recibido</td>
      <td>es</td>
      <td>apparel</td>
    </tr>
    <tr>
      <th>2</th>
      <td>es_0144850</td>
      <td>product_es_0356874</td>
      <td>reviewer_es_0486447</td>
      <td>1</td>
      <td>Tengo que buscar otro sistema, este no funcion...</td>
      <td>Que no aprieta bien en el manillar</td>
      <td>es</td>
      <td>sports</td>
    </tr>
    <tr>
      <th>3</th>
      <td>es_0339629</td>
      <td>product_es_0939832</td>
      <td>reviewer_es_0894703</td>
      <td>1</td>
      <td>Utilicé las brocas de menor diámetro y se me d...</td>
      <td>Brocas de mantequilla</td>
      <td>es</td>
      <td>home_improvement</td>
    </tr>
    <tr>
      <th>4</th>
      <td>es_0858362</td>
      <td>product_es_0489066</td>
      <td>reviewer_es_0887663</td>
      <td>1</td>
      <td>No me gusta su olor a viejo y aspecto malo</td>
      <td>No me gusta</td>
      <td>es</td>
      <td>beauty</td>
    </tr>
  </tbody>
</table>
</div>

<p>The datasets contained products of several categories, but the category didn&#39;t seem to have any effect in the average star rating; the best rated category was eBooks, whose quality is usually average and rating depends on how much the reader likes the content itself. And there was at most two reviews by any of the users or for any product, so there&#39;s no risk of having an extremely forgiving customer or great product throw us off the scent. </p>
<img src="images\p2\output_20_0.png" alt=""  class="center" style="width: 70%;"/>
<img src="images\p2\output_21_0.png" alt=""  class="center" style="width: 70%;"/>
<img src="images\p2\output_22_0.png" alt=""  class="center" style="width: 70%;"/>
<p>So after reviewing the great dataset we had, we started working on the reviews.</p>
<h2 id="processing">Processing</h2>
<h3 id="pre-processing">Pre-processing</h3>
<img src="images\p2\output_27_0.png" alt=""  class="center"/>
<p>Our average review has 27.5 words, in Spanish. So, to make each appearance of any word as standard as possible we put everything in lowercase and replaced accented letters with their unaccented version. Finally we added a column to label the reviews as positive (4 and 5 stars) and negative because, when have we felt great about a purchase and gave it <em>three</em> stars?</p>
<h3 id="tokenization">Tokenization</h3>
<p>The long-honored NLP technique to evaluate a corpus of text by each word. We tokenized out reviews&#39; titles and bodies, but not after having gotten rid of special characters, punctuation marks, misspelt words, numbers and (for now, <em>wink</em>) emojis.</p>
<img src="images\p2\code_limpieza.jpeg" alt="" class="center"/>
<img src="images\p2\code_tokenizar.jpeg" alt="" class="center"/>
<h3 id="lemmatization">Lemmatization</h3>
<p>We used the SpaCy library for this part of our project, because of its well known performance in spanish. It was able to take our reviews and classify most word&#39;s tokens properly with a few lines of code: </p>
<img src="images\p2\code_spacytest.jpeg" alt=""  class="center"/>
<pre><code>       Token  Token Text Token Pos Token Lemma
<span class="hljs-number">0</span>       buscar      buscar      VERB      buscar
<span class="hljs-number">1</span>      sistema     sistema      NOUN     sistema
<span class="hljs-number">2</span>           no          no       ADV          no
<span class="hljs-number">3</span>     funciona    funciona      VERB   funcionar
<span class="hljs-number">4</span>         bien        bien       ADV        bien
<span class="hljs-number">5</span>   abrazadera  abrazadera      NOUN  abrazadera
<span class="hljs-number">6</span>        lleva       lleva      VERB      llevar
<span class="hljs-number">7</span>      agarrar     agarrar      VERB     agarrar
<span class="hljs-number">8</span>     manillar    manillar      VERB    manillar
<span class="hljs-number">9</span>           no          no       ADV          no
<span class="hljs-number">10</span>     aprieta     aprieta      VERB     apretar
<span class="hljs-number">11</span>        bien        bien       ADV        bien
<span class="hljs-number">12</span>  deslizando  deslizando      VERB    deslizar
<span class="hljs-number">13</span>    linterna    linterna      VERB    linterna
<span class="hljs-number">14</span>       hacia       hacia       ADP       hacia
<span class="hljs-number">15</span>       abajo       abajo       ADV      abajar
</code></pre><h3 id="word-frequency-analysis">Word Frequency Analysis</h3>
<p>We started by reviewing which words appear most frequently in negative or positive reviews</p>
<img src="images\p2\output_57_0.png" alt=""  class="center"/>
<img src="images\p2\output_57_1.png" alt=""  class="center"/>
<p>As we can see here, there are plenty words that are common to all reviews, words like &quot;quality&quot;, &quot;product&quot; or &quot;good&quot;, so we got rid of some of these to get a more representative group of words in the categories, with some exceptions that showed themselves to be important further ahead  in the prediction step.</p>
<img src="images\p2\code_removewords.jpeg" alt=""  class="center"/>

<p>So the new top ten words in our reviews are: </p>
<img src="images\p2\output_64_0.png" alt=""  class="center"/>
<img src="images\p2\output_64_1.png" alt=""  class="center"/>

<p>As you can see, although we still have some jack-of-all-trades words, on the lower end of the top ten we are left with very descriptive words like &quot;problem&quot; or &quot;return&quot; for the negative reviews, and &quot;recommend&quot; or &quot;quality/price&quot; in the positive ones. Great!</p>
<p>Lastly, we combined the review titles with their bodies to have all the relevant text in one single feature for our models. Our final dataset was looking like this: </p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>words</th>
      <th>words_rm</th>
      <th>stars</th>
      <th>binario</th>
      <th>words_joint</th>
      <th>words_joint_rm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[malo, comprar, malisimo, grande, demasiar, ap...</td>
      <td>[malo, malisimo, aparatoso, mal, protector]</td>
      <td>1</td>
      <td>0</td>
      <td>malo comprar malisimo grande demasiar aparatos...</td>
      <td>malo malisimo aparatoso mal protector</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[no, recibir, no, recibir, pedir, no, devolucion]</td>
      <td>[no, recibir, no, recibir, no, devolucion]</td>
      <td>1</td>
      <td>0</td>
      <td>no recibir no recibir pedir no devolucion</td>
      <td>no recibir no recibir no devolucion</td>
    </tr>
    <tr>
      <th>2</th>
      <td>[no, apretar, bien, manillar, buscar, sistema,...</td>
      <td>[no, apretar, bien, manillar, buscar, sistema,...</td>
      <td>1</td>
      <td>0</td>
      <td>no apretar bien manillar buscar sistema no fun...</td>
      <td>no apretar bien manillar buscar sistema no bie...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>[broca, mantequilla, utilizar, broca, menor, d...</td>
      <td>[broca, mantequilla, utilizar, broca, menor, d...</td>
      <td>1</td>
      <td>0</td>
      <td>broca mantequilla utilizar broca menor diametr...</td>
      <td>broca mantequilla utilizar broca menor diametr...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>[no, gustar, no, gustar, olor, viejo, aspecto,...</td>
      <td>[no, no, olor, viejo, aspecto, malo]</td>
      <td>1</td>
      <td>0</td>
      <td>no gustar no gustar olor viejo aspecto malo</td>
      <td>no no olor viejo aspecto malo</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="modeling">Modeling</h2>
<h3 id="model-selection">Model Selection</h3>
<p>We decided to evaluate several models on their accuracy, F1 score and confusion matrix. And set our benchmark to be the model that best classified the reviews into positive or negative; out of a <strong>Random Forest</strong> or a <strong>Logistic Regressor</strong> trained with the tokenized dev dataset. </p>
<p>Here&#39;s how they stacked up against each other:</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>Accuracy</th>
      <th>f1_score</th>
      <th>VP</th>
      <th>VN</th>
      <th>FP</th>
      <th>FN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Random Forest</td>
      <td>0.830000</td>
      <td>0.753146</td>
      <td>389</td>
      <td>856</td>
      <td>53</td>
      <td>202</td>
    </tr>
    <tr style="background: #90ee90;">
      <th>0</th>
      <td>Logistic Regressor</td>
      <td>0.838667</td>
      <td>0.794567</td>
      <td>468</td>
      <td>790</td>
      <td>119</td>
      <td>123</td>
    </tr>
  </tbody>
</table>
</div>

<p>This result came after may tweaks to the model hyperparameters and dataset processing of course, but it served as our benchmark as we continued looking for ways to get an accurate classification. </p>
<h4 id="binary-classification">Binary Classification</h4>
<p>Through the exploration of the predictions of this model with differently processed datasets we decided which words to keep in the word elimination step mentioned before.</p>
<p>We trained models with the full tokenized dataset, the removed words dataset, one where we joined the words into bigrams to catch more complex expressions and one were we only joined two words into a bigram if the first word was a variation of &quot;didn&#39;t&quot; to catch things like &quot;didn&#39;t arrive&quot; or &quot;didn&#39;t work&quot;. </p>
<p>We continued using Random Forests and Logistic Regressors, and added a Naive Bayes model since they are generally used for multi-label problems;  the Complement Naive Bayes which is specially common in Bag of Words text problems. These are the evaluation results for all of the models:</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>Accuracy</th>
      <th>f1_score</th>
      <th>VP</th>
      <th>VN</th>
      <th>FP</th>
      <th>FN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Random Forest Tokenized</td>
      <td>0.830000</td>
      <td>0.753146</td>
      <td>389</td>
      <td>856</td>
      <td>53</td>
      <td>202</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Logistic Regressor Tokenized</td>
      <td>0.838667</td>
      <td>0.794567</td>
      <td>468</td>
      <td>790</td>
      <td>119</td>
      <td>123</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Naive Bayes ComplementNB Tokenized</td>
      <td>0.828000</td>
      <td>0.777586</td>
      <td>451</td>
      <td>791</td>
      <td>118</td>
      <td>140</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Random Forest Removed Words</td>
      <td>0.814000</td>
      <td>0.730955</td>
      <td>379</td>
      <td>842</td>
      <td>67</td>
      <td>212</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Logistic Regressor Removed Words</td>
      <td>0.834667</td>
      <td>0.785838</td>
      <td>455</td>
      <td>797</td>
      <td>112</td>
      <td>136</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Naive Bayes ComplementNB Removed Words</td>
      <td>0.828000</td>
      <td>0.777586</td>
      <td>451</td>
      <td>791</td>
      <td>118</td>
      <td>140</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Random Forest Bigram</td>
      <td>0.650000</td>
      <td>0.231332</td>
      <td>79</td>
      <td>896</td>
      <td>13</td>
      <td>512</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Logistic Regressor Bigram</td>
      <td>0.734667</td>
      <td>0.605159</td>
      <td>305</td>
      <td>797</td>
      <td>112</td>
      <td>286</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Naive Bayes ComplementNB Bigram</td>
      <td>0.784000</td>
      <td>0.750769</td>
      <td>488</td>
      <td>688</td>
      <td>221</td>
      <td>103</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Random Forest Did/Didn&#39;t Bigram</td>
      <td>0.821333</td>
      <td>0.744762</td>
      <td>391</td>
      <td>841</td>
      <td>68</td>
      <td>200</td>
    </tr>
    <tr style="background: #90ee90;">
      <th>0</th>
      <td>Logistic Regressor Did/Didn&#39;t Bigram</td>
      <td>0.845333</td>
      <td>0.801370</td>
      <td>468</td>
      <td>800</td>
      <td>109</td>
      <td>123</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Naive Bayes ComplementNB Did/Didn&#39;t Bigram</td>
      <td>0.825333</td>
      <td>0.783828</td>
      <td>475</td>
      <td>763</td>
      <td>146</td>
      <td>116</td>
    </tr>
  </tbody>
</table>
</div>

<p>Quite good overall.</p>
<img src="images\p2\output_124_1.png" alt=""  class="center"/>
<h4 id="5-stars-classification">5 Stars Classification</h4>
<p>With our initial random forest and our simply tokenized model these are some of the positive reviews that were classified as negative </p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_title</th>
      <th>review_body</th>
      <th>words_rm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3006</th>
      <td>bastante completo</td>
      <td>no me gusta las instrucciones en ingles</td>
      <td>[completar, no, instrucción, ingle]</td>
    </tr>
    <tr>
      <th>3007</th>
      <td>cobran mucho por el envio</td>
      <td>llego bien pero el ultimo dia tardo casi una s...</td>
      <td>[cobrar, envio, bien, ultimar, tardar, casi, s...</td>
    </tr>
    <tr>
      <th>3017</th>
      <td>su ligereza</td>
      <td>que es muy ligero aunque un poco bajo y el ple...</td>
      <td>[ligereza, ligero, bajar, plegar, complicar, n...</td>
    </tr>
    <tr>
      <th>3024</th>
      <td>ocupa poco y la ranura es amplia</td>
      <td>la tengo hace menos de un mes y me gusta pero ...</td>
      <td>[ocupar, ranurar, amplio, mes, creer, caro, re...</td>
    </tr>
    <tr>
      <th>3027</th>
      <td>el frigorifico es perfecto el color silver no ...</td>
      <td>el frigorifico es perfecto el color silver no ...</td>
      <td>[frigorifico, perfecto, color, silver, no, rea...</td>
    </tr>
  </tbody>
</table>
</div>

<p>and these are some of the negative ones that were classified as positive:</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_title</th>
      <th>review_body</th>
      <th>words_rm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>259</th>
      <td>entrega tarde</td>
      <td>producto perfecto entrega con seur nefastalleg...</td>
      <td>[entregar, tardar, perfecto, entregar, seur, n...</td>
    </tr>
    <tr>
      <th>1023</th>
      <td>un poco disgustada</td>
      <td>estaba muy ilusionada porque a mi marido siemp...</td>
      <td>[disgustar, ilusionar, maridar, siempre, zippo...</td>
    </tr>
    <tr>
      <th>1420</th>
      <td>bien</td>
      <td>es muy mono relacion calidad precio buena aunq...</td>
      <td>[bien, mono, relacion, bueno, no, maravilloso]</td>
    </tr>
    <tr>
      <th>1598</th>
      <td>calidadprecio perfecto pero ha llegado dañado</td>
      <td>el album genial en relacion calidadprecio pero...</td>
      <td>[calidadprecio, perfecto, dañar, album, genial...</td>
    </tr>
    <tr>
      <th>1610</th>
      <td>el segundo que compro y desilusion</td>
      <td>hace mas de un año compre uno y estaba encanta...</td>
      <td>[segundar, desilusion, año, encantar, problema...</td>
    </tr>
  </tbody>
</table>
</div>

<p>We noticed that the 4 stars reviews were the ones with the highest degree of error, because although the general sentiment is positive they do include some complaints people had with the products and the model takes them as negatives. Followed by 3 stars reviews, in which users might start talking of the positives of the product and do it for longer than they do the complaints.</p>
<p>However, since the Did/Didn&#39;t Bigram dataset proved to be better we trained the models for this classification using it. The computational power needed was definitely a constraint, one of our models took an entire to train! Grid Search + Cross Validation is not kind on our regular computers. The several models we trained for this use case with this dataset tended to get it wrong more often on 2 and 4 stars reviews, unlike the one with only the tokenized words. </p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>Accuracy</th>
      <th>Errores 1</th>
      <th>Errores 2</th>
      <th>Errores 3</th>
      <th>Errores 4</th>
      <th>Errores 5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Naive Bayes ComplementNB Estrellas</td>
      <td>0.458000</td>
      <td>103</td>
      <td>217</td>
      <td>203</td>
      <td>207</td>
      <td>83</td>
    </tr>
    <tr style="background: #90ee90;">
      <th>0</th>
      <td>Random Forest Estrellas</td>
      <td>0.480000</td>
      <td>85</td>
      <td>251</td>
      <td>153</td>
      <td>223</td>
      <td>68</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Ridge Estrellas</td>
      <td>0.448000</td>
      <td>130</td>
      <td>201</td>
      <td>183</td>
      <td>205</td>
      <td>109</td>
    </tr>
    <tr>
      <th>0</th>
      <td>KNN Estrellas</td>
      <td>0.360667</td>
      <td>180</td>
      <td>280</td>
      <td>175</td>
      <td>238</td>
      <td>86</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Nearest Centroid Estrellas</td>
      <td>0.421333</td>
      <td>90</td>
      <td>233</td>
      <td>179</td>
      <td>231</td>
      <td>135</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Passive Agressive Classifier Estrellas</td>
      <td>0.414667</td>
      <td>152</td>
      <td>208</td>
      <td>167</td>
      <td>214</td>
      <td>137</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Perceptron Estrellas</td>
      <td>0.419333</td>
      <td>138</td>
      <td>195</td>
      <td>200</td>
      <td>252</td>
      <td>86</td>
    </tr>
    <tr>
      <th>0</th>
      <td>SGDClassifier Estrellas</td>
      <td>0.457333</td>
      <td>89</td>
      <td>224</td>
      <td>194</td>
      <td>247</td>
      <td>60</td>
    </tr>
  </tbody>
</table>
</div>

<img src="images\p2\output_134_1.png" alt=""  class="center"/>

<h3 id="model-validation">Model Validation</h3>
<p>So after selecting the best models for each of our use cases we put them to the test, training the models on the train dataset and then using them to predict with the data points on the test dataset. </p>
<h4 id="binary-classification-logistic-regression">Binary Classification: Logistic Regression</h4>
<p>Our model to classify the reviews into positive our negative had the following hyperparameters:</p>
<img src="images\p2\code_logreg.jpeg" alt=""  class="center"/>
<p>It Performed marginally better than its benchmark (84% Dev Accuracy)</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>Accuracy</th>
      <th>f1_score</th>
      <th>VP</th>
      <th>VN</th>
      <th>FP</th>
      <th>FN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regressor/td>
      <td>0.8522</td>
      <td>0.813807</td>
      <td>1615</td>
      <td>2646</td>
      <td>354</td>
      <td>385</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="5-star-classification-random-forest">5-Star Classification: Random Forest</h4>
<img src="images\p2\code_random.jpeg" alt=""  class="center"/>
<p>This one too outperformed its dev model by one percentual point (48% Dev Accuracy)</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>Accuracy</th>
      <th>Errores 1</th>
      <th>Errores 2</th>
      <th>Errores 3</th>
      <th>Errores 4</th>
      <th>Errores 5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Random Forest 5 Stars</td>
      <td>0.4904</td>
      <td>154</td>
      <td>861</td>
      <td>536</td>
      <td>702</td>
      <td>295</td>
    </tr>
  </tbody>
</table>
</div>


<h3 id="emoji-exploration">Emoji Exploration</h3>
<p>Since so much of our current online communication depends on emojis, we set out to test these two models with datasets where we used the <strong>Emot</strong> library to convert emojis to a single &quot;word&quot;, like this:</p>
<pre><code>{<span class="hljs-string">'value'</span>: [<span class="hljs-string">'❤'</span>, <span class="hljs-string">'😂'</span>, <span class="hljs-string">'😊'</span>, <span class="hljs-string">'😡'</span>],
 <span class="hljs-string">'location'</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>], [<span class="hljs-number">6</span>, <span class="hljs-number">7</span>]],
 <span class="hljs-string">'mean'</span>: [<span class="hljs-string">':red_heart:'</span>,
  <span class="hljs-string">':face_with_tears_of_joy:'</span>,
  <span class="hljs-string">':smiling_face_with_smiling_eyes:'</span>,
  <span class="hljs-string">':pouting_face:'</span>],
 <span class="hljs-string">'flag'</span>: <span class="hljs-symbol">True</span>}
</code></pre><p>However, after keeping the emojis&#39; meaning in the dev dataset and going through with our other preprocessing steps we found that the models&#39; performance did not improve, it stayed the same or got a little worse. Nonetheless, emojis have gained such a significant place in our communication that they should be included on these kinds of analysis, if not in this case in other like tweets&#39; analysis (X&#39;s analysis?) or forum comments. </p>
<h4 id="binary-classification">Binary Classification</h4>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>Accuracy</th>
      <th>f1_score</th>
      <th>VP</th>
      <th>VN</th>
      <th>FP</th>
      <th>FN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regressor Emoji</td>
      <td>0.847333</td>
      <td>0.804106</td>
      <td>470</td>
      <td>801</td>
      <td>108</td>
      <td>121</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="5-star-classification">5-Star Classification</h4>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Modelo</th>
      <th>Accuracy</th>
      <th>Errores 1</th>
      <th>Errores 2</th>
      <th>Errores 3</th>
      <th>Errores 4</th>
      <th>Errores 5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Random Forest 5 Stars Emoji</td>
      <td>0.466667</td>
      <td>77</td>
      <td>257</td>
      <td>163</td>
      <td>228</td>
      <td>75</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="summing-up-">Summing Up...</h2>
<p>This was a very interesting exercise to dip our toes in NLP, Amazon reviews must be one of the last places online where people from all over the world might love to write honestly about something. </p>
<p>The models clearly performed much better when we looked at this like a binary problem, we obtained our maximum accuracy in this type of models with 85% in the logistic regression that uses the sigmoid function just to predict 0 or 1. To express the feeling of users towards a product classifying a review into positive or negative would be valuable on its own, in this case that information could be used as a visual cue in each comment on the website. But the 5-star system, although more complex and therefore more vulnerable to human fluctuations of mood and subjectivities, allows nuances to be given to that statement of good or bad, and this becomes decisive information for buyers when choosing between two manufacturers of the same product, or two sellers of the same reference. For this exercise it was valuable to convert the problem to binary, and analyzing this information with more about the products and the people who left the reviews would surely show interesting trends.</p>



</body></html>